{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNFxI9tz+0rDmqkgsiCUQlF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kapiloo8/Stock_prediction-using-svm-/blob/main/stock_prediction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "for machine learning we have to import"
      ],
      "metadata": {
        "id": "csI-rOI3Iqtl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score"
      ],
      "metadata": {
        "id": "McC3B8fWHbYz"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "for data manipulation and ploting "
      ],
      "metadata": {
        "id": "6aZuL-0QIw10"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "plt.style.use('seaborn-v0_8-darkgrid')\n",
        "import warnings \n",
        "warnings.filterwarnings(\"ignore\")\n"
      ],
      "metadata": {
        "id": "uoUMjEw0H9E3"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will Read the Stock Data Downloaded From Yahoo Finance Website. The Data Is stored in OHLC(Open, High, Low, Close)  format in a CSV file. To read a CSV file, you can use the read_csv() method of pandas."
      ],
      "metadata": {
        "id": "UFGZNqAuJs3n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/ADANIENT.NS.csv')\n",
        "print(df)"
      ],
      "metadata": {
        "id": "k31XqdTwMVi9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The data needed to be processed before use such that the date column should act as an index to do that"
      ],
      "metadata": {
        "id": "bq8qoT5-Mxkb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Changes The Date column as index columns\n",
        "df.index = pd.to_datetime(df['Date'])\n",
        "df\n",
        "# drop The original date column\n",
        "df = df.drop(['Date'],axis='columns')\n",
        "df"
      ],
      "metadata": {
        "id": "PbecwsjNNCpG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "hL7RdKX4OV1P"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Explanatory or independent variables are used to predict the value response variable. The X is a dataset that holds the variables which are used for prediction. The X consists of variables such as ‘Open – Close’ and ‘High – Low’. These can be understood as indicators based on which the algorithm will predict tomorrow’s trend. Feel free to add more indicators and see the performance"
      ],
      "metadata": {
        "id": "k4E8gTE7OV6h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create predictor variables\n",
        "df['open-close'] = df.Open - df.Close\n",
        "df['high-low']= df.High - df.Low\n",
        "# Store all predictor variables in a variable X\n",
        "x = df[['open-close','high-low']]\n",
        "x.head()\n"
      ],
      "metadata": {
        "id": "43uh9n2lOXe7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "the target variable is the outcome which the machine learning model will predict based on the explanatory variables. y is a target dataset storing the correct trading signal which the machine learning algorithm will try to predict. If tomorrow’s price is greater than today’s price then we will buy the particular Stock else we will have no position in the. We will store +1 for a buy signal and 0 for a no position in y. We will use where() function from NumPy to do this."
      ],
      "metadata": {
        "id": "L9azh2ZNPfwE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y = np.where(df['Close'].shift(-1)>df['Close'],1,0)\n",
        "print(y)"
      ],
      "metadata": {
        "id": "p5ou1LK4PfJ4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will split data into training and test data sets. This is done so that we can evaluate the effectiveness of the model in the test dataset"
      ],
      "metadata": {
        "id": "2xKtQZesQRwF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "split_percentage = 0.8\n",
        "split = int(split_percentage*len(df))\n",
        "#train set data\n",
        "X_train = x[:split]\n",
        "Y_train = y[:split]\n",
        "#test set data\n",
        "X_test = x[split:]\n",
        "Y_test = y[split:]"
      ],
      "metadata": {
        "id": "cXdzEskGQSYp"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will use SVC() function from sklearn.svm.SVC library to create our classifier model using the fit() method on the training data set."
      ],
      "metadata": {
        "id": "5sphSErdR7kG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "param_grid = {'C': [0.1, 1, 10, 100],\n",
        "              'gamma': [0.01, 0.1, 1, 10]}\n",
        "\n",
        "# Create an SVM model with a radial basis function (RBF) kernel\n",
        "svc = SVC(kernel='rbf')\n",
        "\n",
        "# Create a grid search object with cross-validation\n",
        "grid_search = GridSearchCV(svc, param_grid, cv=5)\n",
        "\n",
        "# Fit the grid search object to the training data\n",
        "grid_search.fit(X_train, Y_train)"
      ],
      "metadata": {
        "id": "7neSYGN2eCrC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Best parameters: \", grid_search.best_params_)\n",
        "print(\"Best cross-validation score: \", grid_search.best_score_)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "Z98gcdbyfIkh",
        "outputId": "d21ba89d-1f40-4926-9f68-628108b82ac3"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best parameters:  {'C': 10, 'gamma': 0.01}\n",
            "Best cross-validation score:  0.5732051282051283\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best_svc = grid_search.best_estimator_\n",
        "best_svc.fit(X_train, Y_train)\n",
        "\n",
        "# Make predictions on the test data using the best SVM model\n",
        "Y_pred = best_svc.predict(X_test)\n",
        "\n",
        "# Evaluate the accuracy of the best SVM model on the test data\n",
        "accuracy = accuracy_score(Y_test, Y_pred)\n",
        "print(\"Accuracy score: \", accuracy)"
      ],
      "metadata": {
        "id": "R9ql1Bu5fLtt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Classifier accuracy\n",
        "We will compute the accuracy of the algorithm on the train and test the data set by comparing the actual values of the signal with the predicted values of the signal. The function accuracy_score() will be used to calculate the accuracy."
      ],
      "metadata": {
        "id": "11vI0zJdVsZ9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Make predictions on the entire dataset using the best SVM model\n",
        "df['Predicted_Signal'] = best_svc.predict(x)"
      ],
      "metadata": {
        "id": "Hf7y1CEYaUfc"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate daily returns\n",
        "df['Return'] = df.Close.pct_change()"
      ],
      "metadata": {
        "id": "EuMyfNt_fYi0"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate strategy returns\n",
        "df['Strategy_Return'] = df.Return *df.Predicted_Signal.shift(1)"
      ],
      "metadata": {
        "id": "YkoNRxXEfYoz"
      },
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate Cumulative returns\n",
        "df['Cum_Ret'] = df['Return'].cumsum()\n"
      ],
      "metadata": {
        "id": "wfWjZ_dvaV-c"
      },
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot Cumulative returns\n",
        "df['Cum_Strategy'] = df['Strategy_Return'].cumsum()"
      ],
      "metadata": {
        "id": "l4Z1Pv3NaY57"
      },
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(df['Cum_Ret'],color='red')\n",
        "plt.plot(df['Cum_Strategy'],color='blue')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "yoQ9qdGdfoDf"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}